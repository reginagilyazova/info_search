Соревнование Pri-matrix Factorization на DrivenData с 1ТБ данных — как мы заняли 3 место (перевод)
snakers4
Џривет, •абр! ЏредставлЯю вашему вниманию перевод статьи "
".


…сли вам интересно узнать как мы справились, чему научились, и как вам участвовать в подобном, то прошу под кат. 
‚ своем 
 мы уже писали 
 участвовать в соревнованиЯх. 
Ћтносительно выбора этого соревнованиЯ можно сказать так С в конце 2017 большинство соревнований на каггле были не так интересны и/или давали слишком мало денег при почти нулевой или около того обучающей ценности и/или были со 100+ участниками, которые отправили свои результаты в первый день, потому что последние соревнованиЯ были не таким уж и сложными. Џросто состакай 20 моделей по своему усмотрению. Ќаиболее Яркие примеры из последнего 
 и 
 С интересны только в теории, и ЯвлЯютсЯ не более чем казино с GPU вместо фишек.

Џо этим причинам (достойный приз, отсутствие сильной маркетинговой поддержки из-за 100+ простых заЯвок в первый день, челлендж, интересность и новизна) С мы выбрали этот 
.
‚ этом соревновании Я участвовал вместе с 
 моего телеграм канала (
, 
). „лЯ краткости этот пост будет структурирован таким образом:
—тобы начать, Я собрал список полезных ссылок в том порЯдке, в котором вы вероЯтно должны прочитать их, чтобы решить похожую задачу. „лЯ начала, вы должны быть знакомы с computer vision, базовой математикой (линейнаЯ алгебра, матанализ и численные методы), машинным обучением и базовыми архитектурами в нем.
Џриблизительно на половине соревнованиЯ Я объединилсЯ с ‘аввой ЉолбачЮвым. €значально, перед тем как перейти к полноразмерным видео, Я попробовал какие то штуки с детектированием движениЯ, склеиваниЯ нескольких видео размера 64х64 в одно изображение, матричное разложение. ‘авва пыталсЯ использовать LSTM + какие-то базовые энкодеры длЯ видео размера 64х64, так как у него была машина с карточкой 780GTX так что он мог использовать только микро датасет (64х64 3ѓЃ 2FPS), но даже этого хватало кажетсЯ, чтобы набрать хорошие баллы длЯ попаданиЯ в топ-10 списка. 
Ѓазовый анализ можно посмотреть 
. Љак Я говорил раньше весь датасет весит 1’Ѓ и организаторы соревнованиЯ расшарили его через торрент, но можно было скачать и напрЯмую (но довольно медленно)
‚ наличии было три версии датасета:
‚ целом датасет был хорошего качества С каждое видео было плохо аннотировано, но с учетом размера, это было все равно хорошо С отзывчивый саппорт, можно было качнуть через торренты (правда его запилили довольно поздно с одним сидером в ‘Ђ), и валидационнаЯ часть датасета была просто крутейшаЯ, что Я видел. Ќаша валидациЯ была всегда примерно на 5% меньше, чем потом мы получали на доске. ‚сЮ соревнование занЯло 2 месЯца, но в моем случае ушло 2-3 недели только длЯ того, чтобы скачать датасет и распаковать архив.
…сли честно, Я не особо сильно разбиралсЯ с датасетом, просто потому что он был огромный, но некоторые ключевые инсайты получить было легко.
Њетрика это просто средний logloss по всем 24 классам. ќто хорошо, потому что такаЯ метрика есть почти в каждом DL пакете. ‘ ней довольно легко получить сразу нормальные очки, но при этом она неинтуитивна и ненаглЯдна. Ћчень чувствительно к малейшему количеству ложноположительных предсказаний. Ќу и простое добавление новых моделей эту метрику улучшает, что не очень хорошо в теории.
Љак мы заметили раньше, Я выделил фичи из разных предобученных моделей, вроде resnet152, inception-resnet, inception4 и nasnet. Њы обнаружили, что лучше всего выделЯть фичи не только из последнего слоЯ перед полносвЯзными, но и из skip-connections.
Њы также выделили метаданные вроде ширины, высоты и размера обоих датасетов, микро и оригинального. —то интересно, их комбинациЯ работает намного лучше, чем просто оригинальный датасет. Љак правило, метаданные были очень полезны длЯ определениЯ пустых/не пустых видео, потому что пустые видео обычно весили существенно меньше. ќто позволЯло отделить более 25% пустых видео, что, кстати, самый большой класс по численности:


ђаспределение классов было очень несбалансированным. Ќапример, длЯ "льва" было всего два примера из всей ~200k выборки! Њало того, это были видео с несколькими метками животных, так что это нужно было сделать более специфичное разбиение. Љ счастью, у нас был код с контеста с кегглЯ 
. ‘ таким разбиением наша проверочнаЯ оценка у себЯ всегда была чуточку хуже, чем на доске:


Џосле выделениЯ фич у нас была матрица длЯ каждого видео вида (45,3000), где 45 число кадров, а 3000 число фич длЯ каждого кадра.
Њы обучили 9 моделей, каждаЯ по 5 фолдов, используЯ выделенные фичи:
Њы обнаружили, что 15 эпох + 5 эпох длЯ псевдоразметки должно быть достаточно, чтобы получить довольно приличный результат. ђазмер батча был 64(44/20) длЯ single-feature моделей и 48 (32/16) длЯ nasnet и с concat моделей. ‚ целом, больший батч был лучше. ‚ыбор размера зависел от I/O диска и скорости обучениЯ. „лЯ получениЯ конечного результата, предсказаниЯ из моделей были сложены вместе через 2 полносвЯзных слоЯ метамодели используЯ 10 фолдов.)
Њы обучили 9 моделей, каждаЯ по 5 фолдов, используЯ выделенные фичи:
Њы обнаружили, что 15 эпох + 5 эпох длЯ псевдоразметки должно быть достаточно, длЯ получениЯ довольно приличного результата. ђазмер батча был 64(44/20) длЯ single-feature моделей и 48 (32/16) длЯ nasnet и с concat моделей. ‚ целом, больший батч был всегда лучше. ‚ыбор размера зависел от I/O диска и скорости обучениЯ. „лЯ получениЯ конечного результата, предсказаниЯ из моделей были сложены вместе через 2 полносвЯзных слоЯ метамодели используЯ 10 фолдов.
Ќасколько нам известно, можно было сделать еще пару вещей. Ќапример, попробовать сделать обнаружение объектов на видео 64x64, сделать bbox'ы и транслировать их на полноразмерные видео. ‘делать из этого двух-трех стадийный пайплайн. €ли попробовать построить bbox'ы из дообученных моделей, но это представлЯетсЯ крайне сложным.
Њы сделали более-менее детектирование объектов, но решили не идти этим путем, так как посчитали его ненадежным С не хотелось тратить времЯ на ручную разметку из-за огромного объема данных, плюс мы не верили, что даже на 64x64 детектирование движениЯ будет стабильным.
Њы использовали 3 машины С мой слабенький сервер с 1070Ti, но когда мы поставили туда SSD то стали ограниченны размерами дискового пространства. Ѓыла еще машина ‘аввы со слабеньким GPU и сервер моих друзей с двумЯ 1080Ti.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

