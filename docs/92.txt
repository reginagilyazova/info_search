Асинхронность: назад в будущее
gridem

Асинхронность… Услышав это слово, у программистов начинают блестеть глаза, дыхание становится поверхностным, руки начинают трястись, голос — заикаться, мозг начинает рисовать многочисленные уровни абстракции… У менеджеров округляются глаза, звуки становятся нечленораздельными, руки сжимаются в кулаки, а голос переходит на обертона… Единственное, что их объединяет — это учащенный пульс. Только причины этого различны: программисты рвутся в бой, а менеджеры пытаются заглянуть в хрустальный шар и осознать риски, начинают судорожно придумывать причины увеличения сроков в разы… И уже потом, когда большая часть кода написана, программисты начинают осознавать и познавать всю горечь асинхронности, проводя бесконечные ночи в дебаггере, отчаянно пытаясь понять, что же все-таки происходит… 
 
Именно такую картину рисует мое воспаленное воображение при слове “асинхронность”. Конечно, все это слишком эмоционально и не всегда правда. Ведь так?.. Возможны варианты. Некоторые скажут, что “при правильном подходе все будет работать хорошо”. Однако это можно сказать всегда и везде при всяком удобном и не удобном случае. Но лучше от этого не становится, баги не исправляются, а бессонница не проходит. 
 
Так что же такое асинхронность? Почему она так привлекательна? А главное: что с ней не так? 
 
 Асинхронность на текущий момент является достаточно популярной темой. Достаточно просмотреть последние статьи на хабре, чтобы в этом убедиться. Тут тебе и обзор различных библиотек, и использования языка Go, и всякие асинхронные фреймворки на JS, и много чего другого. 
 
Обычно асинхронность используется для сетевого программирования: всякие сокеты-шмокеты, читатели-писатели и прочие акцепторы. Но бывают еще забавные и интересные события, особенно в UI. Здесь я буду рассматривать исключительно сетевое использование. Однако, как будет показано в следующей статье, подход можно расширять и углублять в неведомые дали. 
 
Чтобы быть совсем уж конкретным, будем писать простой HTTP сервер, который на некий любой запрос посылает некий стандартный ответ. Это чтоб не писать парсер, т.к. к теме асинхронности он имеет ровно такое же отношение, как положение звезд к характеру человека (см. астрологию). 
 
 
 
Хм. Синхронный? А при чем тут синхронный, спросит внимательный читатель, открыв статью про асинхронность. Ну, во-первых, надо же с чего-то начать. С чего-то простого. А во-вторых… Короче, я автор, поэтому будет так. А потом и сами узнаете, зачем. 
 
Для того, чтобы не писать низкоуровневый платформозависимый код, для всех наших целей я буду использовать мощную асинхронную библиотеку под названием  . Благо, статей уже написано про нее достаточно, чтобы быть хотя бы немножко в теме. 
 
Опять же, для большей наглядности и “продакшенности” кода я сделаю обертки для вызова соответствующих функций из библиотеки  . Конечно, кому-то могут нравиться портянки наподобие   или  , но ясность и читабельность кода при этом значительно уменьшается. 
 
Итак, описание сокета и акцептора: 
 
 
Ничего лишнего, просто сервер.   позволяет писать и читать, в том числе до определенных символов ( ).   слушает указанный порт и принимает соединения. 
 
Реализация всего этого хозяйства приведена ниже: 
 
 
Здесь я использовал синглтон для  , чтобы не передавать его каждый раз в сокет явно во входных параметрах. И откуда пользователю знать, что там должен быть какой-то  ? Поэтому я его спрятал подальше, чтобы глаза не мозолил. Остальное, я полагаю, вполне понятно, за исключением, быть может, функции  . Но суть ее проста: читать байтики до тех пор, пока не встретится заветное окончание. Это нужно как раз для HTTP, т.к. заранее размер мы, увы, не можем задать. Приходится ресайзиться. 
 
Давайте теперь напишем долгожданный сервер. Вот он: 
 
 
Сервер готов! 
 
 Недостатки предыдущего сервера очевидны: 
 
Поэтому появляется идея, чтобы обрабатывать соединения в другом потоке, продолжая принимать следующие соединения. Для этого нам понадобится функция создания нового потока, которую я внезапно назову  : 
 
 
Стоит отметить одну забавную вещь: если убрать  , то угадайте, что сделает программа? 
 
 
Теперь можно и сервер написать: 
 
 
Казалось бы, все хорошо, но не тут то было: на реальных задачах под нагрузкой это дело ложится быстро и потом не отжимается. Поэтому умные дядьки подумали, подумали, и решили использовать асинхронность. 
 
 В чем проблема предыдущего подхода? А в том, что потоки вместо реальной работы большую часть времени ожидают на событиях из сети, отжирая ресурсы. Хочется как-то более эффективно использовать потоки для выполнения полезной работы. 
 
Поэтому теперь буду реализовывать аналогичные функции, но уже асинхронно, используя модель проактора. Что это означает? Это означает, что мы для всех операций вызываем функцию и передаем callback, который автомагически позовется по окончании операции. Т.е. нас позовут сами, как только операция завершится. Это отличается от модели реактора, когда мы должны сами вызывать нужные обработчики, наблюдая за состоянием операций. Типичный пример реактора: epoll, kqueue и различные select’ы. Пример проактора:   на Windows. Я буду использовать кроссплатформенный проактор  . 
 
Асинхронные интерфейсы: 
 
 
Стоит остановиться на некоторых вещах: 
 
Если внимательно присмотреться, то отличие от синхронных функций только в том, что асинхронные содержат дополнительный обработчик в качестве входного параметра. 
 
Ну что ж, вроде пока ничего страшного нет. 
 
Реализация: 
 
 
Тут должно быть все понятно, за исключением метода  . Для того, чтобы несколько раз вызывать асинхронное чтение на сокете, необходимо сохранять состояние. Для этого предназначен специальный класс  , который сохраняет текущее состояние асинхронной операции. Похожую реализацию можно встретить в   для различных функций (например  ), которые требуют нескольких вызовов более простых (но не менее асинхронных) операций. 
 
Помимо этого необходимо написать аналог   и диспетчеризацию: 
 
 
Здесь указывается обработчик, который будет запускаться асинхронно в пуле потоков и, собственно, создание пула потоков с последующей диспетчеризацией. 
 
Вот как выглядит реализация: 
 
 
Здесь мы используем   для создания потоков из синхронного подхода. 
 
Реализация сервера: 
 
 
 
Вот такая простыня. С каждым новым вызовом растет вложенность лямбд. Обычно, конечно, такое через лямбды не пишут, т.к. есть сложности с зацикливанием: в лямбду необходимо пробрасывать саму себя, чтобы внутри самой себя позвать саму себя. Но тем не менее, читабельность кода будет примерно одинаковая, т.е. одинаково плохая при сравнении с синхронным кодом. 
 
Итак, давайте обсудим плюсы и минусы асинхронного подхода: 
 
Хорошо, конечно, если все написал правильно и оно сразу заработало и без багов. А вот если это не так… В общем, счастливого дебаггинга, как говорится в таких случаях. И это я еще рассмотрел достаточно простой пример, где можно отследить последовательность вызовов. При небольшом усложнении схемы обработки (например, одновременные чтение и запись в сокеты) сложность кода растет как на дрожжах, а количество багов начинает расти чуть ли не экспоненциально. 
 
Так стоит ли игра свеч? Стоит ли заниматься асинхронностью? На самом деле выход есть — coroutines или  . 
 
 
 
Итак, чего же нам всем хочется?   А хочется простого: использовать плюсы асинхронного и синхронного подходов одновременно, т.е. чтобы и производительность была как у асинхронного, и простота как у синхронного. 
 
На бумаге звучит замечательно. Возможно ли это? Для ответа на вопрос нам понадобится небольшое введение в сопрограммы. 
 
Вот что такое обычные процедуры? Находимся мы, значит, в каком-то месте исполнения и тут раз, и позвали процедуру. Для вызова сначала запоминается текущее место для возврата, затем зовется процедура, она исполняется, завершается и возвращает управление в то место, откуда была позвана. А сопрограмма — это то же самое, только другое: она тоже возвращает управление в то место, откуда была позвана, но при этом она  , а останавливается в некотором месте, с которого дальше продолжает работать при повторном запуске. Т.е. получается эдакий пинг-понг: вызывающий бросает мячик, сопрограмма ловит его, перебегает в другое место, бросает обратно, вызывающий тоже что-то делает (перебегает) и снова бросает в предыдущее место уже сопрограммы. И так происходит до тех пор, пока сопрограмма не завершится. В целом можно сказать, что процедура — это частный случай сопрограммы. 
 
Как теперь это можно использовать для наших асинхронных задач? Ну тут наводит на мысль то, что сопрограмма сохраняет некий контекст исполнения, что для асинхронности крайне важно. Именно это и буду я использовать: если сопрограмме потребуется выполнить асинхронную операцию, то я просто вызову асинхронный метод и выйду из сопрограммы. А обработчик по завершению асинхронной операции просто продолжит исполнение нашей сопрограммы с места последнего вызова той самой асинхронной операции. Т.е. вся грязная работа по сохранению контекста ложится на плечи реализации сопрограмм. 
 
И вот тут как раз и начинаются проблемы. Дело в том, что поддержка сопрограмм на стороне языков и процессоров — дела давно минувших дней. Для реализации переключения контекстов исполнения сегодня необходимо проделать множество операций: сохранить состояния регистров, переключить стек и заполнить некоторые служебные поля для корректной работы среды исполнения (например, для исключений,   и др.). Более того, реализация зависит не только от архитектуры процессора, но еще и от компилятора и операционной системы. Звучит как последний гвоздь в крышку гроба… 
 
К счастью, есть  , которая и реализует все, что необходимо для поддержки конкретной платформы. Написано все на ассемблере, в лучших традициях. Можно, конечно, использовать  , но зачем, когда есть  ? Больше ада и угара! 
 
 Итак, для наших целей напишем свои сопрограммы. Интерфейс будет такой: 
 
 
Вот такой нехитрый интерфейс. Ну и сразу вариант использования: 
 
 
 
Должен выдать на экран: 
 
 
Начнем с метода  : 
 
 
Здесь   создает нам контекст и передает в качестве стартовой функции статический метод  : 
 
 
который просто перенаправляет на метод  , извлекая текущий экземпляр   из  . Вся магия по переключению контекстов находится в приватном методе  : 
 
 
Здесь мы заменяем старое   значение   на новое (нужно для рекурсивного переключения между несколькими сопрограммами), устанавливаем всякие флаги и переключаем контекст с использованием  . После завершения восстанавливаем старые значения и прокидываем исключения в вызывающую функцию. 
 
Смотрим теперь на приватный метод  , который и запускает нужный обработчик: 
 
 
Отмечу один интересный момент: если не сохранить обработчик внутри сопрограммы (до его вызова), то при последующем возврате программа может благополучно упасть. Это связано с тем, что, вообще говоря, обработчик хранит в себе некоторое состояние, которое может быть разрушено в какой-то момент. 
 
Теперь осталось рассмотреть остальные функции: 
 
 
 
 
Теперь пришла очередь реализовать асинхронность на сопрограммах. Тривиальный вариант реализации приведен на следующей диаграмме: 
 
Здесь происходит создание сопрограммы, затем сопрограмма запускает асинхронную операцию и завершает свою работу с использованием функции  . По завершению операции происходит продолжение работы сопрограммы посредством вызова метода  . 
 
И все было бы хорошо, если бы не пресловутая многопоточность. Как это всегда бывает, она вносит некоторую турбулентность, поэтому приведенный выше подход не будет работать должным образом, что наглядно иллюстрирует следующая диаграмма: 
 
Т.е. сразу после шедулинга операции может быть вызван обработчик, который продолжит исполнение до выхода из сопрограммы. Это, понятно, не входило в наши планы. Поэтому придется усложнить последовательность: 
 
Отличие состоит в том, что мы запускаем шедулинг не в сопрограмме, а вне ее, что исключает возможность, описанную выше. При этом продолжение сопрограммы может случиться в другом потоке, что является вполне нормальным поведением, для этого сопрограммы и предназначены, чтобы иметь возможность тусовать их туда-сюда, сохраняя при этом контекст исполнения. 
 
 
 Начнем с реализации функции  : 
 
 
Здесь мы вместо простого запуска обработчика создаем сопрограмму и запускаем обработчик уже внутри нее. Интерес тут также представляет функция  , которая смотрит, не надо ли чего зашедулить: 
 
 
Действия простые: смотрим, есть ли что-то для обработки. Если есть — то выполняем, нет — тогда сопрограмма закончила свою работу и ее можно удалить. 
 
Возникает вопрос: а как заполняется  ? А вот так: 
 
 
Эта функция всегда вызывается внутри сопрограммы. Здесь передается некий обработчик, который будет заниматься шедулингом операций, т.е. запуском асинхронностей. Этот обработчик запоминается, чтобы его запустить по выходу из сопрограммы ( ), после выхода сразу запускается  , который и запускает наш   обработчик. Ниже приведено использование функции   на примере  : 
 
 
  возвращает асинхронный обработчик, который обрабатывает завершение асинхронной операции. Внутри обработчика происходит запоминание ошибки  , чтобы позже иметь возможность пробросить исключение внутри нашей сопрограммы (см. вызов   внутри  ), а затем продолжение исполнение сопрограммы  , т.е. возвращение в метод   сразу после вызова  . Диаграмма ниже показывает последовательность вызовов и взаимодействие различных сущностей: 
 
Остальные функции реализуются аналогично: 
 
 
Везде в реализации я использую соответствующие асинхронные объекты   и  , описанные в пункте про асинхронность. 
 
 Перейдем к использованию нашего функционала. Тут все гораздо проще и изящнее: 
 
 
Приведенный код что-то напоминает… Точно! Это же практически наш синхронный код: 
 Тут ровно одно отличие: в синхронной реализации принятие сокета происходит в главном потоке, а потому отсутствует  . Однако, если задаться целью, можно было бы эти подходы сделать полностью идентичными: для этого в синхронной реализации также сделать принятие сокетов в отдельном потоке, используя  , а функция   тогда просто бы ждала завершения всех потоков. 
 
Но отличие в реализации носит принципиальный характер: получившийся код использует асинхронное сетевое взаимодействие, а значит является гораздо более эффективной реализацией. Собственно на этом наша цель достигнута: сделать симбиоз синхронного и асинхронного подходов, взяв из них самое лучшее, т.е. простоту синхронного и производительность асинхронного. 
 
 
 
Опишу некоторое улучшение для процесса принятия сокетов. Часто, после принятия происходит разветвление исполнения: тот, кто принимал, будет продолжает принимать, а новый сокет будет обрабатываться в отдельном контексте исполнения. Поэтому создадим новый метод  : 
 
 
И тогда наш сервер перепишется в виде: 
 
 
Что гораздо проще для понимания и использования. 
 
 
 
Действительно, отличие от чисто асинхронного подхода в том, что тут возникают дополнительные накладные расходы на создание/переключение контекстов и смежной атрибутики. 
 
Сначала я было хотел проверить предельные нагрузки, но потом оказалось, что даже в одном (!!!) потоке загружается скорее гигабитная сеть, нежели процессор. Поэтому я провел следующий тест: 
 
Результаты приведены в таблице: 
 Отмечу, что погрешность полученных значений связана с колебаниями значений в ходе одного испытания. Скорее всего это связанно с неравномерностью нагрузки канала и обработки. 
 
Тем не менее видно, что не смотря на наличие дополнительного переключения контекстов, а также пробрасыванием исключений вместо кодов возврата (исключение генерится каждый раз при закрытии сокета, т.е. каждый раз на новом запросе) накладные расходы пренебрежимо малы. А если еще добавить код, который бы честно парсил HTTP сообщение, а также код, который бы не менее честно обрабатывал запросы и делал что-нибудь важное и нужное, то можно заявить смело, что  . 
 
 
 
 
 
Вначале возьмем функцию, которая использует асинхронные вызовы. Любую функцию можно превратить в сопрограмму, т.к. функция является частным случаем сопрограммы. Далее возьмем какой-либо асинхронный вызов в такой преобразованной сопрограмме. Такой вызов можно представить в следующем виде: 
 
 
Рассмотрим случай, когда у нас отсутствует код после вызова: 
 
 
Такой код с точки зрения сопрограммы эквивалентен следующему: 
 
 
Т.е. внутри   мы вызываем соответствующую асинхронную функцию  , который нам возвращает управление в сопрограмму по завершению операции, и затем вызывается обработчик   явно. Результат ровно один и тот же. 
 
Теперь осталось рассмотреть более общий случай, когда у нас присутствует код после асинхронного вызова. Такой код эквивалентен: 
 
 
Используя то, что у нас теперь отсутствует код после вызова   внутри  , получаем: 
 
 
Т.е. на один асинхронный вызов стало меньше. Применяя такой подход к каждому асинхронному вызову функции и к каждой функции мы перепишем весь код на сопрограммах.  
 
 Асинхронность стремительным домкратом врывается в нашу программистскую жизнь. Сложности, которые возникают при написании кода, способны привести в дрожь даже самых ярых и закаленных экспертов. Однако, не стоит списывать со счетов старый добрый синхронный подход: в умелых руках асинхронность превращается в элегантные сопрограммы. 
 
В следующей статье будет рассмотрен гораздо более сложный пример, который раскроет всю мощь и потенциал сопрограмм! 
 
До новых встреч в эфире! 
 
 
P.S. Весь код можно найти здесь: 
