Xception: компактная глубокая нейронная сеть
roryorangepants
В последние несколько лет нейронные сети пробрались во все отрасли машинного обучения, но самый большой фурор они бесспорно произвели в области компьютерного зрения. В рамках соревнований 
 было представлено множество различных архитектур свёрточных сетей, которые затем разошлись по фреймворкам и библиотекам.



Чтобы улучшить качество распознавания своих сетей, исследователи старались добавлять в сети больше слоёв, однако со временем пришло понимание, что иногда ограничения производительности попросту не позволяют обучать и использовать настолько глубокие сети. Это стало мотивацией для использования depthwise separable convolutions и создания архитектуры Xception.



Если вы хотите узнать, что это такое, и посмотреть, как использовать такую сеть на практике, чтобы научиться отличать котов от собак, добро пожаловать под кат.





Каждый раз, когда мы добавляем очередной слой в свёрточную сеть, нам нужно принимать стратегическое решение про его характеристики. Какой размер ядра свёртки нам использовать? 3х3? 5х5? А может быть, поставить max pooling? 



В 2015 году была предложена архитектура Inception, идея которой заключалась в следующем: давайте вместо того, чтобы выбирать размер ядра, возьмём несколько вариантов сразу, используем их все одновременно и конкатенируем результаты. Однако это существенно увеличивает количество операций, которые необходимо выполнить для вычисления активаций одного слоя, поэтому авторы 
 предлагают такую хитрость: давайте перед каждым свёрточным блоком делать свёртку с размером ядра 1х1, снижая размерность сигнала, подающегося на вход свёрткам с б
льшими размерами ядер.



Получившаяся на рисунке снизу конструкция и составляет полный модуль Inception.



Но какое отношение это имеет к тому, чтобы сделать нашу сеть более компактной?

В 2016 году Франсуа Шолле (Francois Chollet), автор и разработчик фреймворка Keras, опубликовал 
, в которой предложил пойти дальше и использовать так называемый экстремальный Inception-модуль, также известный как depthwise separable convolution.





Представим, что мы взяли стандартный свёрточный слой с 
 фильтрами размера 3х3, на вход которому подается тензор размерности 
, где 
 — это ширина и высота тензора, а 
 — количество каналов. 

Что делает такой слой? Он сворачивает одновременно все каналы исходного сигнала 
 разными свёртками. На выходе у такого слоя получается тензор размерности 
.



Давайте вместо этого сделаем последовательно два шага:









Давайте разберём конкретный пример. Пусть мы сворачиваем изображение с 16 каналами свёрточным слоем с 32 фильтрами. Суммарно этот свёрточный слой будет иметь 
 весов, так как у нас будет 
 свёрток 3х3.



Сколько же весов будет в аналогичном depthwise separable convolution блоке? Во-первых, у нас будет 
 весов у pointwise convolution. Во-вторых, у нас будет 
 весов у depthwise convolution. В сумме получим 800 весов, что намного меньше, чем у обычного свёрточного слоя.





Обычный свёрточный слой одновременно обрабатывает как пространственную информацию (корреляцию соседних точек внутри одного канала), так и межканальную информацию, так как свёртка применяется ко всем каналам сразу. Архитектура Xception базируется на предположении о том, что эти два вида информации можно обрабатывать последовательно без потери качества работы сети, и раскладывает обычную свёртку на pointwise convolution (которая обрабатывает только межканальную корреляцию) и spatial convolution (которая обрабатывает только пространственную корреляцию в рамках отдельного канала).



Посмотрим на реальный эффект. Для сравнения возьмём две по-настоящему глубоких архитектуры свёрточных сетей — ResNet50 и InceptionResNetV2. 



ResNet50 имеет 25 636 712 весов, а предобученная модель в Keras весит 99 Мб. Точность, которая достигается этой моделью на датасете ImageNet, составляет 75.9%.



InceptionResNetV2 имеет 55 873 736 обучаемых параметров и весит 215 Мб, достигая точности 80.4%.



Что же получается с архитектурой Xception? Сеть имеет 22 910 480 весов и весит 88 Мб. При этом точность классификации на ImageNet составляет 79%.



Таким образом, мы получаем архитектуру сети, которая превосходит по точности ResNet50 и лишь чуть-чуть уступает InceptionResNetV2, при этом 
, а значит по требуемым ресурсам как для обучения, так и для использования этой модели.





Разберём на коротком примере, как применить эту архитектуру к реальной задаче. Для этих целей возьмём датасет 
 с Kaggle и за полчаса научим нашу сеть отличать котиков от собачек.



Разобьем датасет на три части: train (4000 изображений), validation (2000 изображений) и test (10000 изображений).







Так как Франсуа Шолле, автор архитектуры Xception, по совместительству является создателем Keras, он любезно предоставил веса этой сети, обученной на ImageNet, в своём фреймворке, чем мы и воспользуемся, чтобы дотюнить сеть под нашу задачу с помощью transfer learning. 



Загрузим веса с ImageNet в Xception, из которой убраны последние полносвязные слои. Прогоним наш датасет через эту сеть, чтобы получить признаки, которые свёрточная сеть может извлечь из изображений (так называемые bottleneck features):





Создадим полносвязную сеть и обучим её на признаках, полученных из свёрточных слоёв, используя для валидации специально отложенную часть исходного набора данных:





Уже после этой стадии, которая занимает пару минут на видеокарте GeForce GTX 1060, мы получаем accuracy около 99.4% на валидационном датасете.



Теперь попробуем дообучить сеть с аугментацией входных данных, загрузив в свёрточные слои веса с ImageNet, а в полносвязные слои — веса, которые наша сеть выучила только что:





Обучив сеть в таком режиме, ещё за пять эпох (около двадцати минут) мы достигнем точности в 99.5% на валидационном датасете. 



Проверив модель на данных, которых она никогда не видела, и которые не использовались для настройки гиперпараметров (тестовый датасет), увидим точность около 96.9%, что выглядит довольно приемлемо.





Полный код для этого эксперимента можно найти на 
.





В 2017 году Google добавили в TensorFlow предобученные сети архитектуры 
, использующие принципы, похожие на Xception, для того, чтобы сделать модели ещё меньше. Эти модели пригодны для выполнения задач компьютерного зрения прямо на мобильных телефонах или IoT-устройствах, обладающих крайне ограниченными запасами памяти и слабым процессором.



Таким образом, мы незаметно подошли к той точке в истории computer science, когда написать приложение, определяющее, изображена ли на фото птица, можно за пятнадцать минут, причём это приложение будет выполняться прямо на вашем смартфоне.