запускать полноценный кластер на kubernetes с нуль на ubuntu 16 04 danuk уже довольно много написать стать по установка и запуск однако не вс так гладко я потратить несколько сутки на запуск свой кластер дать статья призвать дать исчерпывающий информация не только по установка k8s но и объяснить каждый шаг зачем и почему мы делать именно так как написать это очень важный для успешный запуск кластер подразумевать что у вы более один физический сервер между который и быть распределиться ресурс сервер называться нода nodes обычный хард в k8s не поддерживаться работа с диск происходить по средство распределенный файловый хранилище это необходимый для тот чтобы k8s мочь перемещать контейнер docker на другой нода в случай необходимость без потеря дать файл начинать создание кластер нужно именно с создание свой распределенный файловый хранилище если вы уверить что диск вы никогда не понадобиться то этот шаг можно пропустить я выбрать а ещё рекомендовать почитать этот минимальный разумный количество сервер для ceph 3 можно построить и на один но в это мало смысл из за высокий вероятность потерять дать мы понадобиться flannel он позволять организовать программно определять сеть software defined network sdn именно sdn позволять весь наш контейнер общаться с друг друг внутри кластер установка flannel производиться вместе с k8s и описать ниже в наш пример мы использовать 3 физический сервер установить ubuntu 16 04 на весь сервер не создавать партиции требование k8s предусмотреть в каждый сервер как минимум один диск или партиция для ceph не включать поддержка selinux в ubuntu 16 04 он выключить по умолчание мы назвать сервер так kub01 kub02 kub03 партиция sda2 на каждый сервер создать для ceph форматировать не обязательно установка ceph я описать довольно кратко в сеть много пример и на самый сайт довольно хороший документация весь операция производить из под привелигированый пользователь root создать временной директория установить ceph необходимый создать ключ и разложить он по весь сервер это нужно для утилит ceph deploy возможно вы понадобиться поправить конфига ssh для разрешение логиниться под пользователь root проверить что kub01 не прописать в ваш etc hosts как 127 0 0 1 если прописать удалить этот строка создавать дисковый кластер и инициализировать он проверять наш дисковый кластер можно взять на вооружение следующий полезный команда теперь когда мы убедиться что ceph работать мы создать отдельный пул pool для k8s можно посмотреть весь существующий пул команда ceph df теперь создать отдельный пользователь для наш пул и сохранить ключ ключ понадобиться для доступ k8s к хранилище добавить репозиторий k8s в наш система теперь установить основной пакет инициализировать и запускать k8s именно такой сеть 10 244 0 0 16 необходимый для работа flannel не изменять она сохранить напечатать скрипт команда для присоединение нод к кластер для работа с k8s удобно использовать отдельный непривилегированный пользователь создать он и скопировать в он конфигурационный файл k8s для работа с k8s использоваться утилит использовать она только из под наш пользователь для переход под пользователь выполнимый разрешать запуск контейнер на мастер настраивать право устанавливать flannel сетевой подсистема запустить kube proxy сделать это можно так и пробросить порт 8001 с ваш рабочий машина до сервер kub01 теперь мы мочь зайти в веб интерфейс с свой рабочий машина по адрес открыться веб интерфейс где нужно указать токен получить токен для доступ в веб интерфейс можно так в текущий контроллер отсутствовать бинарник необходимый для работа с поэтому создать свой собственный kube controller manager для создание наш сделать следующий весь команда выполнять из под пользователь root обязательно указывать актуальный версия k8s и дистрибутив ос проверять что наш контроллер успешно создать проверять что в наш образ есть rbd должный увидеть что то вид rbd usr bin rbd usr share man man8 rbd 8 gz заменять стандартный контроллер наш для это править файл заменять строка на обязательно добавлять директива чтобы k8s не пытаться скачивать этот образ из интернет image my kube controller manager v1 9 2 теперь когда запуститься наш контроллер с поддержка rbd мы мочь приступить к настройка связка k8s и ceph на новый сервер выполнить следующий команда мы нужный ключ он можно получить на мастер выполнить команда либо создать он для быстрый и простой установка приложение в k8s быть придумать helm список доступный приложение можно найти p s на написание этот статья уйти 6 часы не судить строго если где то есть опечатка задавать вопрос с радость ответить и помогу

