Xception компактная глубокая нейронная сеть roryorangepants В последние несколько лет нейронные сети пробрались во все отрасли машинного обучения но самый большой фурор они бесспорно произвели в области компьютерного зрения В рамках соревнований было представлено множество различных архитектур св рточных сетей которые затем разошлись по фреймворкам и библиотекам Чтобы улучшить качество распознавания своих сетей исследователи старались добавлять в сети больше сло в однако со временем пришло понимание что иногда ограничения производительности попросту не позволяют обучать и использовать настолько глубокие сети Это стало мотивацией для использования depthwise separable convolutions и создания архитектуры Xception Если вы хотите узнать что это такое и посмотреть как использовать такую сеть на практике чтобы научиться отличать котов от собак добро пожаловать под кат Каждый раз когда мы добавляем очередной слой в св рточную сеть нам нужно принимать стратегическое решение про его характеристики Какой размер ядра св ртки нам использовать 3х3 5х5 А может быть поставить max pooling В 2015 году была предложена архитектура Inception идея которой заключалась в следующем давайте вместо того чтобы выбирать размер ядра возьм м несколько вариантов сразу используем их все одновременно и конкатенируем результаты Однако это существенно увеличивает количество операций которые необходимо выполнить для вычисления активаций одного слоя поэтому авторы предлагают такую хитрость давайте перед каждым св рточным блоком делать св ртку с размером ядра 1х1 снижая размерность сигнала подающегося на вход св рткам с б льшими размерами ядер Получившаяся на рисунке снизу конструкция и составляет полный модуль Inception Но какое отношение это имеет к тому чтобы сделать нашу сеть более компактной В 2016 году Франсуа Шолле Francois Chollet автор и разработчик фреймворка Keras опубликовал в которой предложил пойти дальше и использовать так называемый экстремальный Inception модуль также известный как depthwise separable convolution Представим что мы взяли стандартный св рточный слой с фильтрами размера 3х3 на вход которому подается тензор размерности где это ширина и высота тензора а количество каналов Что делает такой слой Он сворачивает одновременно все каналы исходного сигнала разными св ртками На выходе у такого слоя получается тензор размерности Давайте вместо этого сделаем последовательно два шага Давайте разбер м конкретный пример Пусть мы сворачиваем изображение с 16 каналами св рточным слоем с 32 фильтрами Суммарно этот св рточный слой будет иметь весов так как у нас будет св рток 3х3 Сколько же весов будет в аналогичном depthwise separable convolution блоке Во первых у нас будет весов у pointwise convolution Во вторых у нас будет весов у depthwise convolution В сумме получим 800 весов что намного меньше чем у обычного св рточного слоя Обычный св рточный слой одновременно обрабатывает как пространственную информацию корреляцию соседних точек внутри одного канала так и межканальную информацию так как св ртка применяется ко всем каналам сразу Архитектура Xception базируется на предположении о том что эти два вида информации можно обрабатывать последовательно без потери качества работы сети и раскладывает обычную св ртку на pointwise convolution которая обрабатывает только межканальную корреляцию и spatial convolution которая обрабатывает только пространственную корреляцию в рамках отдельного канала Посмотрим на реальный эффект Для сравнения возьм м две по настоящему глубоких архитектуры св рточных сетей ResNet50 и InceptionResNetV2 ResNet50 имеет 25 636 712 весов а предобученная модель в Keras весит 99 Мб Точность которая достигается этой моделью на датасете ImageNet составляет 75 9 InceptionResNetV2 имеет 55 873 736 обучаемых параметров и весит 215 Мб достигая точности 80 4 Что же получается с архитектурой Xception Сеть имеет 22 910 480 весов и весит 88 Мб При этом точность классификации на ImageNet составляет 79 Таким образом мы получаем архитектуру сети которая превосходит по точности ResNet50 и лишь чуть чуть уступает InceptionResNetV2 при этом а значит по требуемым ресурсам как для обучения так и для использования этой модели Разбер м на коротком примере как применить эту архитектуру к реальной задаче Для этих целей возьм м датасет с Kaggle и за полчаса научим нашу сеть отличать котиков от собачек Разобьем датасет на три части train 4000 изображений validation 2000 изображений и test 10000 изображений Так как Франсуа Шолле автор архитектуры Xception по совместительству является создателем Keras он любезно предоставил веса этой сети обученной на ImageNet в сво м фреймворке чем мы и воспользуемся чтобы дотюнить сеть под нашу задачу с помощью transfer learning Загрузим веса с ImageNet в Xception из которой убраны последние полносвязные слои Прогоним наш датасет через эту сеть чтобы получить признаки которые св рточная сеть может извлечь из изображений так называемые bottleneck features Создадим полносвязную сеть и обучим е на признаках полученных из св рточных сло в используя для валидации специально отложенную часть исходного набора данных Уже после этой стадии которая занимает пару минут на видеокарте GeForce GTX 1060 мы получаем accuracy около 99 4 на валидационном датасете Теперь попробуем дообучить сеть с аугментацией входных данных загрузив в св рточные слои веса с ImageNet а в полносвязные слои веса которые наша сеть выучила только что Обучив сеть в таком режиме ещ за пять эпох около двадцати минут мы достигнем точности в 99 5 на валидационном датасете Проверив модель на данных которых она никогда не видела и которые не использовались для настройки гиперпараметров тестовый датасет увидим точность около 96 9 что выглядит довольно приемлемо Полный код для этого эксперимента можно найти на В 2017 году Google добавили в TensorFlow предобученные сети архитектуры использующие принципы похожие на Xception для того чтобы сделать модели ещ меньше Эти модели пригодны для выполнения задач компьютерного зрения прямо на мобильных телефонах или IoT устройствах обладающих крайне ограниченными запасами памяти и слабым процессором Таким образом мы незаметно подошли к той точке в истории computer science когда написать приложение определяющее изображена ли на фото птица можно за пятнадцать минут прич м это приложение будет выполняться прямо на вашем смартфоне
