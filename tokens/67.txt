Запускаем полноценный кластер на Kubernetes с нуля на Ubuntu 16 04 danuk Уже довольно много написано статей по установке и запуску однако не вс так гладко я потратил несколько суток на запуск своего кластера Данная статья призвана дать исчерпывающую информацию не только по установке k8s но и объяснить каждый шаг зачем и почему мы делаем именно так как написано это очень важно для успешного запуска Кластер подразумевает что у Вас более одного физического сервера между которыми и будут распределятся ресурсы Серверы называются нодами nodes Обычные харды в k8s не поддерживаются Работа с дисками происходит по средствам распределенных файловых хранилищ Это необходимо для того чтобы k8s мог перемещать контейнеры docker на другие ноды в случае необходимости без потери данных файлов Начинать создание кластера нужно именно с создания своего распределенного файлового хранилища Если вы уверены что диски вам никогда не понадобятся то этот шаг можно пропустить Я выбрал А еще рекомендую почитать эту Минимальное разумное количество серверов для Ceph 3 можно построить и на одном но в этом мало смысла из за высокой вероятности потерять данные Нам понадобится Flannel он позволяет организовать программно определяемую сеть Software Defined Network SDN Именно SDN позволяет всем нашим контейнерам общаться с друг другом внутри кластера установка Flannel производится вместе с k8s и описана ниже В нашем примере мы используем 3 физических сервера Установите Ubuntu 16 04 на все сервера Не создавайте партиции требование k8s Предусмотрите в каждом сервере как минимум один диск или партицию для Ceph Не включайте поддержку SELinux в Ubuntu 16 04 он выключен по умолчанию Мы назвали сервера так kub01 kub02 kub03 Партиция sda2 на каждом сервере создана для Ceph форматировать не обязательно Установку Ceph я опишу довольно кратко В сети много примеров и на самом сайте довольно хорошая документация Все операции производим из под привелигированого пользователя root Создадим временную директорию Установим Ceph Необходимо создать ключ и разложить его по всем серверам Это нужно для утилиты ceph deploy возможно вам понадобится поправить конфиг ssh для разрешения логинится под пользователем root Проверьте что kub01 не прописан в вашем etc hosts как 127 0 0 1 если прописан удалите эту строку Создаем дисковый кластер и инициализируем его Проверяем наш дисковый кластер Можно взять на вооружение следующие полезные команды Теперь когда мы убедились что Ceph работает мы создадим отдельный пул pool для k8s можно посмотреть все существующие пулы командой ceph df Теперь создадим отдельного пользователя для нашего пула и сохраним ключи ключи понадобятся для доступа k8s к хранилищу Добавим репозиторий k8s в нашу систему Теперь установим основные пакеты Инициализируем и запускаем k8s именно такая сеть 10 244 0 0 16 необходима для работы flannel не изменяйте ее Сохраните напечатанную скриптом команду для присоединения нод к кластеру Для работы с k8s удобно использовать отдельного непривилегированного пользователя Создадим его и скопируем в него конфигурационный файл k8s Для работы с k8s используется утилита Используем ее только из под нашего пользователя Для перехода под пользователя выполним Разрешаем запуск контейнеров на мастере Настраиваем права Устанавливаем flannel сетевую подсистему Запустим kube proxy сделать это можно так И пробросим порт 8001 с вашей рабочей машины до сервера kub01 Теперь мы можем зайти в веб интерфейс со своей рабочей машины по адресу откроется веб интерфейс где нужно указать токен Получить токен для доступа в веб интерфейс можно так В текущем контроллере отсутствует бинарник необходимый для работы с поэтому создадим свой собственный kube controller manager Для создания нашего сделайте следующее все команды выполняем из под пользователя root обязательно указывайте актуальные версии k8s и дистрибутива ОС Проверяем что наш контроллер успешно создан Проверяем что в нашем образе есть rbd Должны увидеть что то вида rbd usr bin rbd usr share man man8 rbd 8 gz Заменяем стандартный контроллер нашим для этого правим файл Заменяем строку на обязательно добавляем директиву чтобы k8s не пытался скачивать этот образ из интернета Image my kube controller manager v1 9 2 Теперь когда запустился наш контроллер с поддержкой RBD мы можем приступить к настройке связки k8s и Ceph На новом сервере выполните следующие команды Нам нужен ключ Его можно получить на мастере выполнив команду Либо создать его Для быстрой и простой установки приложений в k8s был придуман Helm Список доступных приложений можно найти P S на написание этой статьи ушло 6 часов Не судите строго если где то есть опечатки Задавайте вопросы с радостью отвечу и помогу
